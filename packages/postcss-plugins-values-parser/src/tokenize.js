/*
Copyright Â© 2018 Andrew Powell

This Source Code Form is subject to the terms of the Mozilla Public
License, v. 2.0. If a copy of the MPL was not distributed with this
file, You can obtain one at http://mozilla.org/MPL/2.0/.

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of this Source Code Form.
*/
import { Input } from 'postcss';
import postcssTokenizer from 'postcss/lib/tokenize';

const operators = ['*', '-', '%', '+', '/'];
const operRegex = /([*/])/g;

const brackets = (token, tokenize) => {
	const [, , startLine, startChar, endLine, endChar] = token;
	const part = token[1].slice(1, token[1].length - 1);
	const subTokens = getTokens(part); // eslint-disable-line no-use-before-define

	// adjust line position numbers
	for (const sub of subTokens) {
		if (sub[0] !== 'space') {
			const length = sub[5] - sub[3];
			sub[2] = startLine;
			sub[3] += startChar;
			sub[4] += endLine - 1;
			sub[5] = sub[3] + length;
		}
	}

	const tokens = [['(', '(', startLine, startChar, startLine, startChar], ...subTokens];
	tokens.push([')', ')', startLine, endChar, endLine, endChar]);

	for (const token of tokens.reverse()) {
		tokenize.back(token);
	}
};

const comma = (token, tokenize) => {
	const bits = token[1].split(/([,])/);
	const tokens = [];
	const [, , startLine, , endLine] = token;
	let [, , , startChar, , endChar] = token;

	for (let bit of bits) {
		bit = bit || ',';
		const name = bit === ',' ? 'comma' : 'word';

		if (bit !== bits[0]) {
			startChar = endChar + 1;
		}

		endChar = startChar + bit.length - 1;

		tokens.push([name, bit, startLine, startChar, endLine, endChar]);
	}

	for (const tokn of tokens.reverse()) {
		tokenize.back(tokn);
	}
};

export const getTokens = (what) => {
	const input = new Input(what, {});
	const tokenize = tokenizer(input); // eslint-disable-line no-use-before-define
	const result = [];

	// this shouldn't ever be slow as the string being tokenized will always be small
	while (!tokenize.endOfFile()) {
		const token = tokenize.nextToken();
		result.push(token);
	}

	return result;
};

const operator = (token, tokenize) => {
	const [, value, startLine, , endLine, endChar] = token;
	const parts = value.split(operRegex);
	let [, , , startChar] = token;

	const tokens = parts.map((part) => {
		const type = operators.includes(part) ? 'operator' : 'word';
		const newToken = [type, part, startLine, startChar, endLine, endChar];

		startChar += part.length;

		return newToken;
	});

	for (const tokn of tokens.reverse()) {
		tokenize.back(tokn);
	}
};

export const tokenizer = (...args) => {
	const tokenize = postcssTokenizer(...args);
	const ogNextToken = tokenize.nextToken;

	tokenize.nextToken = (...nextArgs) => {
		let token = ogNextToken(...nextArgs);

		if (!token) {
			return token;
		}

		const [type, value] = token;

		// TODO: need to adjust the line/char offsets
		if (type === 'brackets') {
			brackets(token, tokenize);
			token = ogNextToken(...nextArgs);
		} else if (type === 'word') {
			if (operators.includes(value)) {
				token[0] = 'operator';
			} else if (operRegex.test(value)) {
				operator(token, tokenize);
				token = ogNextToken(...nextArgs);
			} else if (value.length > 1 && value.includes(',')) {
				comma(token, tokenize);
				token = ogNextToken(...nextArgs);
			}
		}

		return token;
	};

	return tokenize;
};
